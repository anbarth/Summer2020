import time
import random
import numpy as np
from sho import shoEigenbra
from myStats import mean,stdev
from linReg import regress
import matplotlib.pyplot as plt
import csv
import multiprocessing as mp

# computes slope & intercept for a single (n1,n2) value
# follows the same algorithm as oldInterceptsHeatMap (see july 14 for pseudocode)
# in each trial, each set of N random vectors is generated in parallel (asynchronous execution)

### SET UP
tic = time.time()
random.seed()

# parameters
n1 = 2
n2 = 5
left = -20
right = 20
dx = 0.05
Nlist = [5,10,25,50,150,500,1000]
sampleSize = 500
trials = 10

# dimension of discretized position space
D = int((right-left)/dx)

# get all eigenfunctions
eigens = np.zeros((2,D))
eigens[0] = shoEigenbra(n1,dx,left,right)
eigens[1] = shoEigenbra(n2,dx,left,right)

### FUNCTION TO RUN IN PARALLEL
# gives an estimation of < psi_n1 | psi_n2 > using N random vectors
def calcOverlap(N):
    psizeta = np.zeros((2,N))
    # pick N random vectors
    for k in range(N):
        zeta = [random.choice([-1,1]) for x in range(D)] # <z|
        # TODO some complex conjugate nonesense might be needed here
        psizeta[0][k] = np.dot(eigens[0], zeta) # <psi_n1|z>
        psizeta[1][k] = np.dot(eigens[1], zeta) # <psi_n2|z>
        
    return np.vdot(psizeta[0], psizeta[1])*(1.0/N) 


### RUN TRIALS

# the sigmas that will comprise my ln(sigma) vs. ln(N) plot
avgSig = np.zeros((len(Nlist),1))
avgSig_err = np.zeros((len(Nlist),1))

# go through every value of N and find sigma for each
for N_index in range(len(Nlist)):
    N = Nlist[N_index]
    
    avgOverlaps = np.zeros((trials)) # each trial's average(<n1|n2> estimates)
    sigmas = np.zeros((1,trials)) # each trial's stdev(<n1|n2> estimates) (it's 2D bc its 2D in the full heatmap code)
    for i in range(trials):
        # one trial: 
        # set up parallel processing
        pool = mp.Pool(mp.cpu_count())
        # take a sample of <n1|n2>s generated by different sets of N random vectors
        overlaps_results = [pool.apply_async(calcOverlap,args=[N]) for j in range(sampleSize)]
        pool.close()
        pool.join()
        overlaps = [r.get() for r in overlaps_results]
        # record the avg and stdev of this sample of <n1|n2>s
        avgOverlaps[i] = mean(overlaps)
        sigmas[0][i] = stdev(overlaps)
    
    # each trial gave me an estimate of sigma -- find avg & std err of these sigmas
    avgSig[N_index] = mean(sigmas[0])
    avgSig_err[N_index] = stdev(sigmas[0]) / np.sqrt(trials)
    print(mean(avgOverlaps)) # as the code runs, i eyeball these to check that the overlap is near what it should be -- just a sanity check

### REGRESSION
# here's the data i wanna work with
lnN = [np.log(N) for N in Nlist]
lnSigma = [np.log(avgSig[x]) for x in range(len(Nlist))]
lnSigma_err = [avgSig_err[x] / avgSig[x] for x in range(len(Nlist))]

# regress!
(slope, intercept, r_sq, slope_err, intercept_err) = regress(lnN, lnSigma)

### WRITE OUTPUT
with open('n1n2.csv','w') as csvFile:
    writer = csv.writer(csvFile, delimiter=',')

    # write specs abt this run
    writer.writerow(['n1='+str(n1)+', n2='+str(n2)+'. dx='+str(dx)+' over ['+str(left)+','+str(right)+']'])
    writer.writerow(['sample size: '+str(sampleSize)+', '+str(trials)+' trials'])

    # write slope and intercept
    writer.writerow(['slope',slope[0],'slope err',slope_err])
    writer.writerow(['incpt',intercept[0],'incpt err',intercept_err])

    # write ln sigma vs ln N
    writer.writerow(['ln N','ln sigma','ln sigma err'])
    for i in range(len(Nlist)):
        writer.writerow([lnN[i],lnSigma[i][0],lnSigma_err[i][0]])



toc = time.time()
print("runtime (s): "+str(toc-tic))
slopeS = str(int(slope[0]*10000)/10000.0)
slope_errS = str(int(slope_err*10000)/10000.0)
interS = str(int(intercept[0]*1000)/1000.0)
inter_errS = str(int(intercept_err*1000)/1000.0)
print("slope: "+slopeS+" +/- "+slope_errS)
print("intercept: "+interS+" +/- "+inter_errS)

